{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logbook and all things for Monte-Carlo Minimizor-Maximization\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "\n",
    "1. Monte-Carlo Descent method to search for optimal point\n",
    "\n",
    "-   Use a gradient-based local optimization method\n",
    "    -   This requires auto-grad by Jax/PyTorch/TensorFlow.\n",
    "    -   Use Jax for now.\n",
    "-   Use MCTD to balance exploration and exploitation of the search space\n",
    "\n",
    "2. Learn the lower bound of the objective function\n",
    "\n",
    "-   Use a quadratic model to approximate the lower bound of the objective function\n",
    "-   The learning is as a linear regression problem: finding `A`, such that `Ax <= y`\n",
    "\n",
    "3. Use interval computation to estimate if the optimal point is found within a small box\n",
    "\n",
    "-   Use ibex to compute the interval of the objective function\n",
    "\n",
    "4. Use branch-and-bound to split the search space into smaller boxes\n",
    "\n",
    "-   Better approx -> better pruning\n",
    "-   Prunning ambig box -> high priority\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo code\n",
    "\n",
    "```\n",
    "MCMM: (function, box, local_opt, budget)\n",
    "    create a root node\n",
    "    while in budget:\n",
    "        random samples to create new nodes (new step)\n",
    "        select a path from root to leaf L by UCT\n",
    "        do local opt on L\n",
    "```\n",
    "\n",
    "```\n",
    "initialize a box B\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "initialize count to 0\n",
    "for each element e in the array:\n",
    "    if e is greater than 10:\n",
    "        increment count by 1\n",
    "return count\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems to solve\n",
    "\n",
    "Use an toy example  \n",
    "$\\min( 1000*(x+1)^2-3, (x-1)^2-1)$\n",
    "\n",
    "-   During MCTD optimization, we have\n",
    "    -   A list of samples from each trajectory\n",
    "    -   A best-found point (x=1) from 1 or more nodes (but it is not the global min)\n",
    "    -   0 or more local best-found from 1 or more nodes\n",
    "\n",
    "3. Use interval computation to estimate if the optimal point is found within a small box\n",
    "\n",
    "-   interval + function -> Ibex -> interval (can't tell directly when the formula is sat)\n",
    "    -   Use IBEX to find a small box B' that $f == lb_f$ may occur in\n",
    "-   Better LB, better pruning?\n",
    "    -   IBEX works better with quadratic instead of linear.\n",
    "    -   The best lb to learn is a function that is NEITHER tightly lb to original function NOR completely flat\n",
    "-   Learned small box B', restart by another MCTD?\n",
    "    -   No. Sample within the box for another node on MCTD\n",
    "    -   We need a global LB for the original function, not a piecewise LB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Settings\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "1. Synthetic functions\n",
    "\n",
    "-   [SFU](https://www.sfu.ca/~ssurjano/optimization.html)\n",
    "-   [Kyoto](http://www-optima.amp.i.kyoto-u.ac.jp/member/student/hedar/Hedar_files/TestGO_files/Page364.htm)\n",
    "\n",
    "2. Coconut Project (Maybe too old?)\n",
    "\n",
    "-   [Coconut](https://arnold-neumaier.at/glopt/coconut/Benchmark/Benchmark.html)\n",
    "\n",
    "3. Real Large Scale Global Optimization\n",
    "\n",
    "-   [CEC](https://github.com/P-N-Suganthan/2022-SO-BO/blob/main/CEC2022%20TR.pdf)\n",
    "\n",
    "4. Engineering problems\n",
    "\n",
    "-   [Matlab](https://www.mathworks.com/matlabcentral/fileexchange/124810-benchmark-problems?s_tid=FX_rc1_behav)\n",
    "\n",
    "5. Optimization of Black-Box Functions\n",
    "\n",
    "-   [Black-Box](https://github.com/christiangeissler/gradoptbenchmark/tree/master/)\n",
    "\n",
    "6. Sets of test problems for MINLP\n",
    "\n",
    "-   [MINLP](https://www.minlp.com/nlp-and-minlp-test-problems)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines\n",
    "\n",
    "1. [Gurobi]() - installed\n",
    "2. [Scipy.optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html) - installed\n",
    "3. [PyGMO](https://esa.github.io/pagmo2/docs/cpp/algorithms/nlopt.html) - TODO\n",
    "4. [BARON](https://sahinidis.coe.gatech.edu/baron) - can do via [NEOS](https://neos-server.org/neos/)\n",
    "\n",
    "-   BARON guarantees to provide global optima under fairly general assumptions, but cannot handle constraints containing a goniometric function, an if-then-else statement or a reference to an external function. BARON requires that all nonlinear variables and expressions in the mathematical program are bounded from below and above. [source](https://documentation.aimms.com/platform/solvers/baron.html)\n",
    "\n",
    "4. Gradient based ? check if there are in `scipy.optimize` or `pygmo`\n",
    "5. Simulated Annealing ? check if there are in `scipy.optimize` or `pygmo`\n",
    "\n",
    "6. [Matlab FMinCon](https://www.mathworks.com/help/optim/ug/fmincon.html) - installed, but least priority because it is not free and not in python\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Memo\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a result table\n",
    "\n",
    "| Function Name      | Best Result | Best Result Time | Average Result       | Average Result Time |\n",
    "| ------------------ | ----------- | ---------------- | -------------------- | ------------------- |\n",
    "| Levy - 10d         | 1.68e-12    | ~ 20s            | 1.44 +- 2.14         | ~ 20s               |\n",
    "| Levy - 50d         | 4.86e-10    | ~ 60s            | 7.07 +- 11.08        | ~ 60s               |\n",
    "| Levy - 100d        | 3.64e-08    | ~ 120s           | 20.31 +- 30.28       | ~ 120s              |\n",
    "| Levy - 500d        | 1.34e-04    | ~ 1200s          | 117.43 +- 178.05     | ~ 1200s             |\n",
    "| Ackley - 10d       | 1.73e-09    | ~ 20s            | 7.33 +- 12.45        | ~ 20s               |\n",
    "| Ackley - 50d       | 4.86e-08    | ~ 60s            | 64.99 +- 105.35      | ~ 60s               |\n",
    "| Ackley - 100d      | 2.74e-06    | ~ 120s           | 489.23 +- 678.59     | ~ 120s              |\n",
    "| Ackley - 500d      | 3.45e-01    | ~ 1200s          | 56929.07 +- 87258.25 | ~ 1200s             |\n",
    "| Schwefel - 10d     | 2.81e-10    | ~ 20s            | 106.39 +- 147.55     | ~ 20s               |\n",
    "| Schwefel - 50d     | 1.10e-08    | ~ 60s            | 4433.81 +- 6447.66   | ~ 60s               |\n",
    "| Schwefel - 100d    | 1.22e-06    | ~ 120s           | 23868.55 +- 32918.32 | ~ 120s              |\n",
    "| Schwefel - 500d    | 4.81e+02    | ~ 1200s          | 1.29e+08 +- 1.93e+08 | ~ 1200s             |\n",
    "| Drop Wave - 10d    | 1.11e-05    | ~ 20s            | 2.48 +- 3.69         | ~ 20s               |\n",
    "| Drop Wave - 50d    | 1.25e-04    | ~ 60s            | 36.59 +- 55.83       | ~ 60s               |\n",
    "| Drop Wave - 100d   | 1.11e-03    | ~ 120s           | 139.46 +- 201.42     | ~ 120s              |\n",
    "| Drop Wave - 500d   | 2.54e+01    | ~ 1200s          | 37845.81 +- 60035.78 | ~ 1200s             |\n",
    "| Michalewicz - 10d  | 1.03e-02    | ~ 20s            | 2.17 +- 3.22         | ~ 20s               |\n",
    "| Michalewicz - 50d  | 6.21e+00    | ~ 20s            |\n",
    "| Michalewicz - 100d |\n",
    "| Michalewicz - 500d |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of results from different random seeds\n",
    "\n",
    "-   For Levy 50d\n",
    "\n",
    "```\n",
    "best_found_history = [\n",
    "11.162158012390137,\n",
    "4.864455505071419e-10,\n",
    "34.244049072265625,\n",
    "2.0835724812151568e-10,\n",
    "8.990206718444824,\n",
    "0.08952824026346207,\n",
    "0.2685847580432892,\n",
    "1.8039302825927734,\n",
    "]\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jax]",
   "language": "python",
   "name": "conda-env-jax-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
